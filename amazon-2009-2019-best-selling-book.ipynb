{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Amazon Best Selling Book Data Analysis\n\n## Business Understanding\n\nAmazon has a huge books collection for its customers to buy or borrow. customers can give rating to the books n a 5 star scale after buy i, the people give rating can be professionals such as journalists or editors, but also can be anyone with a point of view in a specific area or amatures. The rating system is based on a score and a detailed text review. The rating can be used to recommand books to others for deciding whether to purchase a particular book or not.\n\nIn this notebook, I have got the data called \"Amazon's best selling book between 2009 and 2019\", and will analyze the authors, the genres and the most valueable book in this dataset.  therefor, I list out 3 business qustions to answer from the exporing:\n\n\n#### Who are the most popular top 10 authors ?\n#### How to give weighted rating to all the books?\n#### How sells distribution in the perspective of genres ?"},{"metadata":{},"cell_type":"markdown","source":"## Data acquisition and understanding\nFirst , we need to import useful libraries and the dataset."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\npd.set_option(\"display.width\", 350)\n[([root] + dirname + file)[0] for root, dirname, file in os.walk('/kaggle/input') if len(file)>0 ][0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/amazon-top-50-bestselling-books-2009-2019/bestsellers with categories.csv')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Understanding Data\nTo understanding the data , we need to have a overview of the data, including rows and columns , the size is also interesting."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> After first load and check, the data set has 550 rows and 7 columns\n> To clean the content we need to prepare Data"},{"metadata":{},"cell_type":"markdown","source":"## Prepare Data\n\n### Remove Duplications\n\nSome books appeared in different years. and the price may be different.  \nGenre should be the same, but need to check reviews and ratings\nI need to merge books with the same title, reviews, and ratings ."},{"metadata":{"trusted":true},"cell_type":"code","source":"#check duplicates by .duplicated\ndf.duplicated(subset=['Name', 'User Rating', 'Reviews']).sum()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then we have 198 books can be merged."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1 First, find out all count of books with the same name and rating.\nname_grouped = df.groupby([\"Name\", 'User Rating', 'Reviews']).count()\n\n# 2 list out which count is bigger than 1, means duplicated\nduplication = name_grouped.loc[(name_grouped['Author'] > 1)]\n\nduplication\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we have 97 books was republished.\nTo identify a book, I choose not only name but also rating and reviews.  so  I can safty merge them.  and can simply pick the newest version/latest year. The years are already sorted, so we can just pick the **last entry** of each duplicate.\n\nRef: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html\n\nThen we can safty merge these duplicates from original dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"merge_duplication=df.drop_duplicates(subset=['Name', 'User Rating', 'Reviews'],keep = 'last',inplace = False)\nmerge_duplication","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"check if we have anymore duplicated rows"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check again\nmerge_duplication.reset_index().duplicated(['Name', 'User Rating', 'Reviews']).sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove Price 0 \n\nWe can see in the dataframe description that some items are priced at 0. which may give wrong ratings comparing with normal books"},{"metadata":{"trusted":true},"cell_type":"code","source":"price0 = merge_duplication.loc[merge_duplication['Price'] == 0]\nprice0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will remove these 7 rows from merge_duplication,   then I can get the prepared dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cleaned = merge_duplication.drop(price0.index)\ndf_cleaned","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get a Quick Overview\n\n\nTo understand out business question better, I need under stand the dataset better, here are several questions need to be answered:\n\n\nHow many books one author can publish? \nAnd How many books can they publish in total? "},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_by_df_cleaned = df_cleaned.value_counts('Author')\n\ntop_popular= sorted_by_df_cleaned[:10]\n\nplt.figure(figsize=(20,5))\nsns.barplot(top_popular.index, top_popular.values)\n\nplt.title('Top 10 Authors with the Most Books')\nplt.ylabel('# Number of Books')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see the top 10 authors with the most books published, Rick Riordan is the most popular author. Stephen King is the 10th "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cleaned.loc[df_cleaned['Author'].isin(list(top_popular.index))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To answer the questions , One author can have up to 10 books, and top 10 author published 62 books"},{"metadata":{},"cell_type":"markdown","source":"### Bayesian average\n\n> From the overview, I can see there is a problem that the number of voting is small for less famouse books.\n> To solve this matter, 'Bayesian average' is ideal to be interduced here. \n\n*inspired by https://www.kaggle.com/paotografi/amazon-2009-2019-best-selling-book-eda*\n\nMy understanding is, the intuition of Bayesian average is considering the min and average value from dataset when evaluate a single element.\nIndividual value needs to caculate with group factors together which is \"outside information\".\nIn this way, books having a fewer votes can get weighted rating to compete with books having more votes \n\nFrom wifikepdia:\nhttps://en.wikipedia.org/wiki/Bayesian_average\n\n\nIMDB use it to give a weighted rating also, and here is imdb explanation: \n*How does IMDB calculate the rank of movies and TV shows on the Top Rated Movies and Top Rated TV Show lists?\nThe following formula is used to calculate the Top Rated 250 titles. This formula provides a true 'Bayesian estimate', which takes into account the number of votes each title has received, minimum votes required to be on the list, and the mean vote for all titles*\n\n'Bayesian estimate' from imdb: \nhttps://help.imdb.com/article/imdb/track-movies-tv/ratings-faq/G67Y87TFYYP6TWAV?ref_=helpms_helpart_inline#calculate\n\n\nTo utilize Bayesian estimate, there are 4 variables need to be considerated:\n\n1. v = votes, reviews received by the author, number of people give rating\n2. m = min votes, the lowest reviews one author can get in dataset.\n3. R = mean rating, received by the author\n4. C = mean rating, of the dataset\n\nThen we calculate the weighted rating using Bayesian average in this way:\n\nweighted_rating = (R * v / v + m ) + ( C * m / v + m)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# to get m and c\nm = merge_duplication['Reviews'].min()\nC = merge_duplication['User Rating'].mean()\n['min review:',m,'mean rating:',C]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare variables\nauthor_counts = df_cleaned.value_counts('Author')\nauthor_names=author_counts.index\nvoutes=author_counts.values\nauthor_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to initialize v and R \nratings_sum=np.zeros(len(author_counts))\nv=np.zeros(len(author_counts))\nR=np.zeros(len(author_counts))\nratings=np.zeros(len(author_counts))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to get weighted_rating list\nget_rating_sum = lambda x: df_cleaned.loc[df_cleaned['Author'] == author_names[x], 'User Rating'].sum()\nget_votes = lambda x: df_cleaned.loc[df_cleaned['Author'] == author_names[x], 'Reviews'].sum()\nfor i in range(0, len(author_counts)):\n    ratings_sum[i] = get_rating_sum(i)\n    R[i] = ratings_sum[i] / voutes[i]\n    v[i] = get_votes(i)\n    \n    ratings[i]=(R[i] * v[i] + C * m )/(v[i]+m)\n\nratings[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#put author rating into dataframe\ndf_rating=pd.DataFrame({\n    'Author': author_names,\n    'Books Written': author_counts,\n    'Reviews': v,\n    'Average Rating': R,\n    'Weighted Rating': ratings\n})\ndf_rating['Average Rating']=df_rating['Average Rating'].round(decimals=4)\ndf_rating.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"after get weighted ratings, I can redo the rank to authors"},{"metadata":{"trusted":true},"cell_type":"code","source":"top_rating=df_rating.nlargest(10 ,['Weighted Rating'])\nplt.figure(figsize=(20,6))\nsns.barplot(top_rating['Author'], top_rating['Weighted Rating'])\nplt.title('Top 10 Authors with weighted Ratings')\n\nplt.ylim(top_rating['Weighted Rating'].min()-0.0001,top_rating['Weighted Rating'].max()+0.0001)\nplt.ylabel('Weighted Ratings')\nplt.show()\n\ntop_rating","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The new result is different that the total count of books published. Dav Pilkey  has heightest rating.\n"},{"metadata":{},"cell_type":"markdown","source":"### The Genre\n\nTry to look into Genre category, , and find out how many groups we have by group and sum."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cleaned.groupby('Genre').count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It shows that there are move Non Fiction book in the book list"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cleaned.groupby('Genre').sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"because it only have 2 categories,  we can simply rename the Gerne to isFiction, and the value to be true or false"},{"metadata":{"trusted":true},"cell_type":"code","source":"is_fiction = df_cleaned.rename(columns={'Genre': 'isFiction'}).replace({'isFiction': {'Fiction': True, 'Non Fiction': False}})\n\nis_fiction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"genre_reviews = is_fiction.groupby(\"isFiction\")[\"Reviews\"].sum()\ngenre_ratings = is_fiction.groupby(\"isFiction\")[\"User Rating\"].sum()\ngenre_reviews_avg = is_fiction.groupby(\"isFiction\")[\"Reviews\"].mean()\ngenre_ratings_avg = is_fiction.groupby(\"isFiction\")[\"User Rating\"].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1. v = votes/reviews received by the author, number of people give rating\n#2. m = min votes, the lowest reviews one author can get in dataset.\n#3. R = mean rating, received by the author\n#4. C = mean rating, of the dataset\n\nvs = genre_reviews\nm = df_cleaned['Reviews'].min()\nC = df_cleaned['User Rating'].mean()\nRs = genre_ratings_avg\nw_rating=np.zeros(2)\n\nfor i in range(0,len(genre_reviews.index)):\n    R = Rs[i]\n    v = vs[i]\n    w_rating[i]=(R * v/(v+m))+(C * m/(v+m))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(10,6))\nsns.barplot(genre_reviews.index,w_rating)\n\nplt.ylim(w_rating.min()-0.01, w_rating.max() + 0.01)\nplt.title('Books Fiction or Non Fiction Weighted Rating')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the comparision shows that Fiction book have better ratings thatn non-fiction"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
